pml_training <- read_csv("Data/pml-training.csv")
install.packages(tidyverse)
install.packages("tidyverse")
library(dplyr)
library(tidyverse)
pml_training <- read_csv("Data/pml-training.csv")
pml_testing <- read_csv("Data/pml-testing.csv")
dim(pml_training)
dim(pml_testing)
summarise(pml_training)
View(pml_training)
table(pml_training$classe)
pml_training <- as.factor(pml_training)
pml_training$classe <- as.factor(pml_training$classe)
pml_training <- read_csv("Data/pml-training.csv")
pml_testing <- read_csv("Data/pml-testing.csv")
rm(list=ls())
pml_training <- read_csv("Data/pml-training.csv")
pml_testing <- read_csv("Data/pml-testing.csv")
pml_training$classe <- as.factor(pml_training$classe)
pml_testing$classe <- as.factor(pml_testing$classe)
getwd()
knitr::opts_chunk$set(echo = TRUE)
summary(pml_training)
set.seed(1903)
rm(list=ls())
training_set <- read.csv("Data/pml-training.csv")
validation_set <- read.csv("Data/pml-testing.csv")
set.seed(1234)
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)  # Change this to .75
library(rpart)
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)  # Change this to .75
library(rpart.plot)
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)  # Change this to .75
library(caret)
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)  # Change this to .75
trainData<- training_set[, colSums(is.na(training_set)) == 0]
validData <- validation_set[, colSums(is.na(validation_set)) == 0]
head(training_set)
View(training_set)
trainData2 <- trainData %>% select(-c("X1","user_name","raw_timestamp_part1",
"raw_timestamp_part2", "cvtd_timestamp",
"new_window", "new_number"))
trainData2 <- trainData %>% select(-c("X","user_name","raw_timestamp_part1",
"raw_timestamp_part2", "cvtd_timestamp",
"new_window", "new_number"))
trainData2 <- trainData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "new_number"))
trainData2 <- trainData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
validData2 <- validData2 %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
validData2 <- validData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
set.seed(1234)
inTrain <- createDataPartition(trainData2$classe, p = 0.7, list = FALSE)  # Change this to .75
trainData <- trainData[inTrain, ]
testData <- trainData[-inTrain, ]
trainData2 <- trainData[inTrain, ]
testData2 <- trainData[-inTrain, ]
rm(list=ls())
training_set <- read.csv("Data/pml-training.csv")
validation_set <- read.csv("Data/pml-testing.csv")
trainData<- training_set[, colSums(is.na(training_set)) == 0]
validData <- validation_set[, colSums(is.na(validation_set)) == 0]
rm(training_set, validation_set)
trainData <- trainData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
validData <- validData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
set.seed(1234)
inTrain <- createDataPartition(trainData$classe, p = 0.7, list = FALSE)  # Change this to .75
trainData <- trainData[inTrain, ]
testData <- trainData[-inTrain, ]
NZV <- nearZeroVar(trainData)
trainData <- trainData[, -NZV]
testData  <- testData[, -NZV]
dim(trainData)
cor_mat <- cor(trainData[, -53])
corrplot(cor_mat, order = "FPC", method = "color", type = "upper",
tl.cex = 0.8, tl.col = rgb(0, 0, 0))
install.packages("corrplot")
library(corrplot)
corrplot(cor_mat, order = "FPC", method = "color", type = "upper",
tl.cex = 0.8, tl.col = rgb(0, 0, 0))
highlyCorrelated = findCorrelation(cor_mat, cutoff=0.75)
names(trainData)[highlyCorrelated]
decisionTreeMod1 <- rpart(classe ~ ., data=trainData, method="class")
fancyRpartPlot(decisionTreeMod1)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
fancyRpartPlot(decisionTreeMod1)
library(caret)
library(kernlab)
library(dplyr)
library(tidyverse)
training_set <- read.csv("Data/pml-training.csv")
validation_set <- read.csv("Data/pml-testing.csv") # We leave this to the end
training_set$classe <- as.factor(training_set$classe)
trainData<- training_set[, colSums(is.na(training_set)) == 0]
trainData <- trainData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
validData <- validation_set[, colSums(is.na(validation_set)) == 0]
validData <- validData %>% select(-c("X","user_name","raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp",
"new_window", "num_window"))
mostlyNA <- sapply(trainData, function(x) mean(is.na(x))) > 0.95
trainData <- trainData[, mostlyNA==F]
NZV <- nearZeroVar(trainData)
trainData <- trainData[, -NZV]
testData  <- testData[, -NZV]
dim(trainData)
inTrain <- createDataPartition(trainData$classe,
p = 0.7, list = FALSE)
training <- trainData[inTrain, ]
testing <- trainData[-inTrain, ]
?train
modelFit_1 <- train(classe ~ ., data = training, method = "class",)
library(rpart)
library(rpart.plot)
modelFit_1 <- train(classe ~ ., data = training, method = "class",)
library(randomForest)
modelFit_1 <- train(classe ~ ., data = training, method = "class",)
modelFit_1 <- rpart(classe ~ ., data = training, method = "class",)
modelFit_1
fancyRpartPlot(modelFit_1)
library(rpart.plot)
fancyRpartPlot(modelFit_1)
library(RColorBrewer)
modelFit_1 <- rpart(classe ~ ., data = training, method = "class",)
modelFit_1 # Look at model
fancyRpartPlot(modelFit_1)
install.packages("rpart.plot")
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modelFit_1)
library(rpart.plot)
library(rattle)
fancyRpartPlot(modelFit_1)
fancyRpartPlot(modelFit_1)
predictTreeMod1 <- predict(modelFit_1, testing, type = "class")
cmtree <- confusionMatrix(predictTreeMod1, testData$classe)
library(gbm)
cmtree <- confusionMatrix(predictTreeMod1, testData$classe)
library(caret)
cmtree <- confusionMatrix(predictTreeMod1, testData$classe)
cmtree <- confusionMatrix(predictTreeMod1, testing$classe)
cmtree
cmtree
modelFit_2<- randomForest(classe ~. , data=training)
library(caret)
library(kernlab)
library(dplyr)
library(tidyverse)
library(rpart)
library(randomForest)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
library(gbm)
modelFit_2<- randomForest(classe ~. , data=training)
Pred_modelFit_2 <- predict(modelFit_2, testing, type = "class")
fancyRpartPlot(modelFit_1)
confusionMatrix(Pred_modelFit_2, myTesting$classe)
confusionMatrix(Pred_modelFit_2, testing$classe)
plot(modelFit_1)
plot(modelFit_2)
qplot(modelFit_2)
plot(modelFit_2)
title(main = "Random Forest Errors")
plot(modelFit_2, main = "Random Forest Errors")
plot(modelFit_2, main = "Random Forest Errors",
sub = "Number of Trees")
plot(modelFit_2, main = "Random Forest Errors",
xlab = "Number of Trees")
plot(modelFit_2, main = "Random Forest Errors",
xlab = "Number of Trees")
plot(modelFit_2, main = "Random Forest Errors",
xlab = "Number of Trees",
sub = NULL)
fancyRpartPlot(modelFit_1)
plot(modelFit_2, main = "Random Forest Errors",
xlab = "Number of Trees",
sub = NULL)
plot(modelFit_2, main = "Random Forest Errors",
xlab = "Number of Trees",
ylab = "Error Rate")
plot(modelFit_2)
plot(modelFit_2, main = "Random Forest Errors",
xlab = "Number of Trees",
ylab = "Error Rate")
plot(modelFit_2, main = "Random Forest Errors",
#xlab = "Number of Trees",
ylab = "Error Rate")
plot(modelFit_2, main = "Random Forest Errors",
#xlab = "Number of Trees",
ylab = "Error Rate")
plot(modelFit_2, main = "Random Forest Errors")
modelFit_3 <- train(classe ~., method = "gbm", data = training, verbose = FALSE)
print(modelFit_3)
qplot(predict(modelFit_3, testing), wage, data=testing)
qplot(predict(modelFit_3, testing), classe, data=testing)
qplot(predict(modelFit_3, testing), classe, data=validData)
qplot(predict(modelFit_3, testing), classe, data = training)
qplot(predict(modelFit_3, testing), classe, data = testing)
